{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c411caf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import pyspark \n",
    "import copy\n",
    "import math\n",
    "import rawpy\n",
    "import random\n",
    "import matplotlib\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from torch import nn\n",
    "from PIL import Image\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Conv2DTranspose, UpSampling2D, Conv2D\n",
    "from tensorflow.keras.layers import LSTM,Embedding,Dropout,Reshape\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import lib\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB7\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "torch.manual_seed(11)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "matplotlib.use('pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd1d8be",
   "metadata": {},
   "source": [
    "# ./Training  2_class_fire_or_no_fire_winter\n",
    "\n",
    "### https://ieee-dataport.org/open-access/flame-dataset-aerial-imagery-pile-burn-detection-using-drones-uavs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "97b20653",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_path = \"./Training\"\n",
    "train_path_fire = train_path+ \"/Fire\"\n",
    "train_path_no_fire = train_path+ \"/No_Fire\"\n",
    "\n",
    "\n",
    "dataset = \"./Training\"\n",
    "output_pdf = True\n",
    "output_statistics = False\n",
    "image_size = 224\n",
    "model_name = 'mobilenet_v2'\n",
    "hidden_layers = [128, 64, 32]\n",
    "num_classes = 2\n",
    "batch_size = 16\n",
    "epochs = 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d0d19422",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_pdf(history, model_name):\n",
    "    print(\"Generating pdf for \" + model_name)\n",
    "\n",
    "    # grab the desired metrics from tf history\n",
    "    desired_metrics = ['accuracy', 'loss', 'val_accuracy', 'val_loss']\n",
    "    metrics_to_plot = dict((k, history.history[k]) for k in desired_metrics if k in history.history)\n",
    "\n",
    "    df = pd.DataFrame(metrics_to_plot)\n",
    "    df.index = range(1, len(df)+1)\n",
    "    df.rename(columns={'accuracy': 'Training Accuracy', 'loss': 'Training Loss',\n",
    "        'val_accuracy': 'Validation Accuracy', 'val_loss': 'Validation Loss'}, inplace=True)\n",
    "    print(df)\n",
    "    sns.set()\n",
    "    ax = sns.lineplot(marker='o', dashes=False, data=df)\n",
    "    ax.set_xticks([1, 2, 3, 4, 5])\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_yticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "    ax.set_ylabel('Value')\n",
    "    ax.set_title('Model Loss and Accuracy')\n",
    "    plt.savefig(f'./model_statistics/{model_name}_plot.pdf')\n",
    "\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f8eeb279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " model_14 (Functional)       (None, 7, 7, 1280)        2257984   \n",
      "                                                                 \n",
      " conv2d_transpose_54 (Conv2D  (None, 9, 9, 16)         184336    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_55 (Conv2D  (None, 11, 11, 32)       4640      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " up_sampling2d_25 (UpSamplin  (None, 22, 22, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_transpose_56 (Conv2D  (None, 24, 24, 32)       9248      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_57 (Conv2D  (None, 26, 26, 64)       18496     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " up_sampling2d_26 (UpSamplin  (None, 52, 52, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_transpose_58 (Conv2D  (None, 54, 54, 128)      73856     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_59 (Conv2D  (None, 56, 56, 128)      147584    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 56, 56, 1)         1153      \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 3136)              0         \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 128)               401536    \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,109,235\n",
      "Trainable params: 851,251\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "METRICS = ['accuracy',\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall')]\n",
    "\n",
    "# baseModel = EfficientNetB7(\n",
    "#     include_top=False, pooling='avg', weights='imagenet')\n",
    "\n",
    "baseModel = tf.keras.applications.MobileNetV2(\n",
    "    alpha=1.0,\n",
    "    input_shape= (224, 224, 3),\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    pooling='avg'\n",
    ")\n",
    "\n",
    "baseModel = tf.keras.Model(baseModel.input, baseModel.get_layer(name = \"out_relu\").output )\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Transfer Learning\n",
    "model.add(baseModel)\n",
    "model.layers[0].trainable = False  \n",
    "model.add(Conv2DTranspose(16, kernel_size=(3,3), activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Conv2DTranspose(32, kernel_size=(3,3), activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2DTranspose(32, kernel_size=(3,3), activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Conv2DTranspose(64, kernel_size=(3,3), activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(UpSampling2D((2, 2)))   \n",
    "model.add(Conv2DTranspose(128, kernel_size=(3,3), activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Conv2DTranspose(128, kernel_size=(3,3), activation='relu', kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Conv2D(1, kernel_size=(3, 3), activation='sigmoid', padding='same'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "for layer in range(len(hidden_layers)):\n",
    "    model.add(Dense(hidden_layers[layer], activation='relu'))\n",
    "\n",
    "# Add our classification layer and display model properties\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "#opt = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "# Compile the sections into one NN\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
    "              metrics=METRICS)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e2fa4a4c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 39375 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "2461/2461 [==============================] - 169s 67ms/step - loss: 0.0675 - accuracy: 0.9755 - precision: 0.9755 - recall: 0.9755 - lr: 0.0100\n",
      "Epoch 2/10\n",
      "2461/2461 [==============================] - 166s 67ms/step - loss: 0.0136 - accuracy: 0.9954 - precision: 0.9954 - recall: 0.9954 - lr: 0.0100\n",
      "Epoch 3/10\n",
      "2461/2461 [==============================] - 171s 70ms/step - loss: 0.0057 - accuracy: 0.9981 - precision: 0.9981 - recall: 0.9981 - lr: 0.0100\n",
      "Epoch 4/10\n",
      "2461/2461 [==============================] - 168s 68ms/step - loss: 0.0046 - accuracy: 0.9983 - precision: 0.9983 - recall: 0.9983 - lr: 0.0100\n",
      "Epoch 5/10\n",
      "2461/2461 [==============================] - 163s 66ms/step - loss: 0.0017 - accuracy: 0.9994 - precision: 0.9994 - recall: 0.9994 - lr: 0.0100\n",
      "Epoch 6/10\n",
      "2461/2461 [==============================] - 169s 69ms/step - loss: 0.0010 - accuracy: 0.9997 - precision: 0.9997 - recall: 0.9997 - lr: 0.0100\n",
      "Epoch 7/10\n",
      "2461/2461 [==============================] - 162s 66ms/step - loss: 0.0013 - accuracy: 0.9996 - precision: 0.9996 - recall: 0.9996 - lr: 0.0100\n",
      "Epoch 8/10\n",
      "2461/2461 [==============================] - 159s 64ms/step - loss: 8.8305e-04 - accuracy: 0.9997 - precision: 0.9997 - recall: 0.9997 - lr: 0.0100\n",
      "Epoch 9/10\n",
      "2461/2461 [==============================] - 159s 64ms/step - loss: 4.8564e-04 - accuracy: 0.9998 - precision: 0.9998 - recall: 0.9998 - lr: 1.0000e-03\n",
      "Epoch 10/10\n",
      "2461/2461 [==============================] - 159s 64ms/step - loss: 1.4433e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - lr: 1.0000e-03\n",
      "Generating pdf for mobilenet_v2\n",
      "    Training Accuracy  Training Loss\n",
      "1            0.975517       0.067489\n",
      "2            0.995429       0.013613\n",
      "3            0.998146       0.005742\n",
      "4            0.998324       0.004578\n",
      "5            0.999416       0.001718\n",
      "6            0.999695       0.001035\n",
      "7            0.999568       0.001289\n",
      "8            0.999746       0.000883\n",
      "9            0.999848       0.000486\n",
      "10           0.999975       0.000144\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "data_generator = ImageDataGenerator(\n",
    "        preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input)\n",
    "\n",
    "train_generator = data_generator.flow_from_directory(\n",
    "    f'{dataset}',\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "num_training_files = len(train_generator.filepaths)\n",
    "\n",
    "\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=3)\n",
    "lrr= ReduceLROnPlateau(monitor='accuracy',   factor=.1,   patience=2,  min_lr=1e-5) \n",
    "\n",
    "# The division by 5 here is to make training quicker\n",
    "# when you want maximum accuracy remove it.\n",
    "history =  model.fit(train_generator, epochs=epochs, callbacks=[lrr,es_callback])\n",
    "\n",
    "create_pdf(history, \"mobilenet_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf31726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testmobilenet_v2\n",
      "Found 8617 images belonging to 2 classes.\n",
      "408/538 [=====================>........] - ETA: 14s - loss: 2.3062 - accuracy: 0.7217 - precision: 0.7217 - recall: 0.7217"
     ]
    }
   ],
   "source": [
    "data_generator = ImageDataGenerator(\n",
    "        preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input)\n",
    "\n",
    "print(\"Test\" + model_name)\n",
    "test_generator = data_generator.flow_from_directory(\n",
    "                f'./Test',\n",
    "                target_size=(image_size, image_size),\n",
    "                batch_size=batch_size,\n",
    "                class_mode='categorical',\n",
    "                shuffle=False)\n",
    "num_files = len(test_generator.filepaths)\n",
    "\n",
    "steps = num_files/batch_size\n",
    "\n",
    "model.evaluate(test_generator, steps=steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ab6fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f'./3_models_series/mobilenet_v2/{model_name}_2_fire_or_no_fire_winter.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d677a7",
   "metadata": {},
   "source": [
    "# ./FIRE-SMOKE-DATASET/FIRE-SMOKE-DATASET/Train 3_classes_fire_neutral_smoke\n",
    "\n",
    "### https://github.com/DeepQuestAI/Fire-Smoke-Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc1f94d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "dataset = \"./FIRE-SMOKE-DATASET/FIRE-SMOKE-DATASET/Train\"\n",
    "output_pdf = True\n",
    "output_statistics = False\n",
    "image_size = 224\n",
    "model_name = 'mobilenet_v2'\n",
    "hidden_layers = [128, 64, 32]\n",
    "num_classes = 3\n",
    "batch_size = 64\n",
    "epochs = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7889085",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = ['accuracy',\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall')]\n",
    "\n",
    "# baseModel = EfficientNetB7(\n",
    "#     include_top=False, pooling='avg', weights='imagenet')\n",
    "\n",
    "baseModel = tf.keras.applications.MobileNetV2(\n",
    "    alpha=1.0,\n",
    "    input_shape= (224, 224, 3),\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    pooling='avg'\n",
    ")\n",
    "\n",
    "baseModel = tf.keras.Model(baseModel.input, baseModel.get_layer(name = \"out_relu\").output )\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Transfer Learning\n",
    "model.add(baseModel)\n",
    "model.layers[0].trainable = True  \n",
    "model.add(Conv2DTranspose(16, kernel_size=(3,3), activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Conv2DTranspose(32, kernel_size=(3,3), activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2DTranspose(64, kernel_size=(3,3), activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(UpSampling2D((2, 2)))   \n",
    "model.add(Conv2DTranspose(128, kernel_size=(3,3), activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Conv2D(1, kernel_size=(3, 3), activation='sigmoid', padding='same'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "for layer in range(len(hidden_layers)):\n",
    "    model.add(Dense(hidden_layers[layer], activation='relu'))\n",
    "\n",
    "# Add our classification layer and display model properties\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "# Compile the sections into one NN\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
    "              metrics=METRICS)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee411043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "data_generator = ImageDataGenerator(\n",
    "        preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input)\n",
    "\n",
    "train_generator = data_generator.flow_from_directory(\n",
    "    f'{dataset}',\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "num_training_files = len(train_generator.filepaths)\n",
    "\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=3)\n",
    "lrr= ReduceLROnPlateau(monitor='accuracy',   factor=.1,   patience=2,  min_lr=1e-5) \n",
    "\n",
    "# The division by 5 here is to make training quicker\n",
    "# when you want maximum accuracy remove it.\n",
    "history =  model.fit(train_generator, epochs=epochs, callbacks=[lrr,es_callback])\n",
    "\n",
    "\n",
    "\n",
    "create_pdf(history, \"mobilenet_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260f76b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(\n",
    "        preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input)\n",
    "\n",
    "print(\"Test\" + model_name)\n",
    "test_generator = data_generator.flow_from_directory(\n",
    "        f'FIRE-SMOKE-DATASET/FIRE-SMOKE-DATASET/Test',\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "num_files = len(test_generator.filepaths)\n",
    "\n",
    "steps = num_files/batch_size\n",
    "\n",
    "model.evaluate(test_generator, steps=steps)\n",
    "\n",
    "generateStatistics(model, test_generator, model_name, num_classes, steps, loss, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a79366",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f'./3_models_series/mobilenet_v2/{model_name}_3_fire_smoke_neutral.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2e8bb6",
   "metadata": {},
   "source": [
    "# E:\\Facultate\\Siva_master\\Projects\\git\\change_detection\\fire_smoke\\Dataset\\Training and Validation  2_class_fire_or_no_fire\n",
    "\n",
    "### https://data.mendeley.com/datasets/gjmr63rz2r/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98835877",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = \"./fire_smoke/Dataset/Training and Validation\"\n",
    "output_pdf = True\n",
    "output_statistics = False\n",
    "image_size = 224\n",
    "model_name = 'mobilenet_v2'\n",
    "hidden_layers = [128, 64, 32]\n",
    "num_classes = 2\n",
    "batch_size = 64\n",
    "epochs = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c33551",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = ['accuracy',\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall')]\n",
    "\n",
    "# baseModel = EfficientNetB7(\n",
    "#     include_top=False, pooling='avg', weights='imagenet')\n",
    "\n",
    "baseModel = tf.keras.applications.MobileNetV2(\n",
    "    alpha=1.0,\n",
    "    input_shape= (224, 224, 3),\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    pooling='avg'\n",
    ")\n",
    "\n",
    "baseModel = tf.keras.Model(baseModel.input, baseModel.get_layer(name = \"out_relu\").output )\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Transfer Learning\n",
    "model.add(baseModel)\n",
    "model.layers[0].trainable = True  \n",
    "model.add(Conv2DTranspose(16, kernel_size=(3,3), activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Conv2DTranspose(32, kernel_size=(3,3), activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2DTranspose(64, kernel_size=(3,3), activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(UpSampling2D((2, 2)))   \n",
    "model.add(Conv2DTranspose(128, kernel_size=(3,3), activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Conv2D(1, kernel_size=(3, 3), activation='sigmoid', padding='same'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "for layer in range(len(hidden_layers)):\n",
    "    model.add(Dense(hidden_layers[layer], activation='relu'))\n",
    "\n",
    "# Add our classification layer and display model properties\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "# Compile the sections into one NN\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
    "              metrics=METRICS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453a44be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "data_generator = ImageDataGenerator(\n",
    "        preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input)\n",
    "\n",
    "train_generator = data_generator.flow_from_directory(\n",
    "    f'{dataset}',\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "num_training_files = len(train_generator.filepaths)\n",
    "\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=3)\n",
    "lrr= ReduceLROnPlateau(monitor='accuracy',   factor=.1,   patience=2,  min_lr=1e-5) \n",
    "\n",
    "# The division by 5 here is to make training quicker\n",
    "# when you want maximum accuracy remove it.\n",
    "history =  model.fit(train_generator, epochs=epochs, callbacks=[lrr,es_callback])\n",
    "\n",
    "\n",
    "\n",
    "create_pdf(history, \"mobilenet_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e64249d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(\n",
    "        preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input)\n",
    "\n",
    "print(\"Test\" + model_name)\n",
    "test_generator = data_generator.flow_from_directory(\n",
    "        f'fire_smoke/Dataset/Testing',\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "num_files = len(test_generator.filepaths)\n",
    "\n",
    "steps = num_files/batch_size\n",
    "\n",
    "model.evaluate(test_generator, steps=steps)\n",
    "\n",
    "generateStatistics(model, test_generator, model_name, num_classes, steps, loss, accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1446d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f'./3_models_series/mobilenet_v2/{model_name}_2_fire_or_no_fire.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63399512",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
